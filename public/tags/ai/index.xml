<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on David Robert - Data Scientist / ML Engineer</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in AI on David Robert - Data Scientist / ML Engineer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Power of RAG in Modern LLMs</title>
      <link>http://localhost:1313/blog/second-post/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/second-post/</guid>
      <description>Retrieval-Augmented Generation (RAG) is a powerful technique that combines the generative power of Large Language Models (LLMs) with the factual grounding of an external knowledge base. This approach helps to reduce hallucinations and provide more accurate, up-to-date responses. In this post, we&amp;rsquo;ll explore the basic architecture of a RAG system.</description>
    </item>
  </channel>
</rss>
